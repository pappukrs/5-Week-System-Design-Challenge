## **ğŸ“… Day 6: Event-Driven Architecture (EDA) with Kafka & RabbitMQ ğŸš€**  
Today, we will **explore Event-Driven Architecture (EDA)** and implement it using **Kafka and RabbitMQ** with a hands-on **Node.js microservices demo**.

---

# **ğŸ“Œ Part 1: What is Event-Driven Architecture (EDA)?**
### **ğŸ”¹ Definition:**  
EDA is a **design pattern** where services communicate by **producing and consuming events**, rather than making direct API calls.

### **ğŸ”¹ Key Concepts:**
- **Event Producer** â†’ Generates an event (e.g., Order Created)
- **Event Broker (Kafka/RabbitMQ)** â†’ Routes and stores events
- **Event Consumer** â†’ Reacts to events (e.g., Send Email when Order is Created)

### **ğŸ”¹ Benefits of EDA:**
âœ… **Decoupling** â†’ Microservices can work independently  
âœ… **Scalability** â†’ Handles high loads efficiently  
âœ… **Resilience** â†’ Events are stored until processed  

---

# **ğŸ“Œ Part 2: Understanding Kafka & RabbitMQ**
| Feature  | **Kafka**  | **RabbitMQ**  |
|----------|-----------|--------------|
| **Type**  | Distributed Log System | Message Broker |
| **Best For**  | Event Streaming (Big Data, Logs)  | Message Queueing (Tasks, Jobs) |
| **Message Retention** | Stores events for days | Deletes messages after consumption |
| **Performance** | High Throughput | Low Latency |

---

# **ğŸ“Œ Part 3: Hands-on - Kafka & RabbitMQ with Node.js**
Weâ€™ll create **two microservices**:
1. **Producer Service** â†’ Sends events (`Order Created`)  
2. **Consumer Service** â†’ Listens for events (`Send Email`)  

---

## **ğŸ›  Step 1: Set Up Kafka & RabbitMQ with Docker**
ğŸ“ **Create `docker-compose.yml`**
```yaml
version: '3'
services:
  kafka:
    image: bitnami/kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_CFG_ZOOKEEPER_CONNECT: "zookeeper:2181"
      ALLOW_PLAINTEXT_LISTENER: "yes"
  
  zookeeper:
    image: bitnami/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"

  rabbitmq:
    image: rabbitmq:3-management
    container_name: rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672" # Management UI
```

ğŸ”¥ **Start the containers**
```bash
docker-compose up -d
```

---

## **ğŸ›  Step 2: Install Node.js Dependencies**
```bash
npm init -y
npm install express kafka-node amqplib
```

---

## **ğŸ›  Step 3: Implement Kafka Producer & Consumer**
ğŸ“ **Create `kafkaProducer.js`**
```js
const kafka = require("kafka-node");

const client = new kafka.KafkaClient({ kafkaHost: "localhost:9092" });
const producer = new kafka.Producer(client);

producer.on("ready", () => {
    console.log("âœ… Kafka Producer is ready");

    const message = JSON.stringify({ orderId: 123, status: "Created" });
    producer.send([{ topic: "order-events", messages: message }], (err, data) => {
        if (err) console.error("âŒ Kafka Error:", err);
        else console.log("ğŸ“¨ Kafka Event Sent:", data);
    });
});
```

ğŸ“ **Create `kafkaConsumer.js`**
```js
const kafka = require("kafka-node");

const client = new kafka.KafkaClient({ kafkaHost: "localhost:9092" });
const consumer = new kafka.Consumer(client, [{ topic: "order-events", partition: 0 }], { autoCommit: true });

consumer.on("message", (message) => {
    console.log("ğŸ“¥ Kafka Event Received:", JSON.parse(message.value));
});
```

ğŸ”¥ **Run Kafka Services**
```bash
node kafkaProducer.js  # Sends event
node kafkaConsumer.js  # Listens for event
```

ğŸ“¢ **Expected Output:**
```
ğŸ“¨ Kafka Event Sent: { order-events: '123' }
ğŸ“¥ Kafka Event Received: { orderId: 123, status: 'Created' }
```

---

## **ğŸ›  Step 4: Implement RabbitMQ Producer & Consumer**
ğŸ“ **Create `rabbitProducer.js`**
```js
const amqp = require("amqplib");

async function sendOrder() {
    const connection = await amqp.connect("amqp://localhost");
    const channel = await connection.createChannel();

    const queue = "orderQueue";
    await channel.assertQueue(queue, { durable: false });

    const order = { orderId: 456, status: "Created" };
    channel.sendToQueue(queue, Buffer.from(JSON.stringify(order)));

    console.log("ğŸ“¨ RabbitMQ Event Sent:", order);
    setTimeout(() => connection.close(), 500);
}

sendOrder();
```

ğŸ“ **Create `rabbitConsumer.js`**
```js
const amqp = require("amqplib");

async function receiveOrder() {
    const connection = await amqp.connect("amqp://localhost");
    const channel = await connection.createChannel();

    const queue = "orderQueue";
    await channel.assertQueue(queue, { durable: false });

    console.log("ğŸ“¥ RabbitMQ Consumer is waiting...");
    channel.consume(queue, (msg) => {
        console.log("ğŸ“¥ RabbitMQ Event Received:", JSON.parse(msg.content.toString()));
    }, { noAck: true });
}

receiveOrder();
```

ğŸ”¥ **Run RabbitMQ Services**
```bash
node rabbitProducer.js  # Sends event
node rabbitConsumer.js  # Listens for event
```

ğŸ“¢ **Expected Output:**
```
ğŸ“¨ RabbitMQ Event Sent: { orderId: 456, status: 'Created' }
ğŸ“¥ RabbitMQ Event Received: { orderId: 456, status: 'Created' }
```

---

# **ğŸ“Œ Part 4: Kafka vs. RabbitMQ - Which One to Choose?**
| Feature  | **Kafka** | **RabbitMQ** |
|----------|---------|-------------|
| **Message Retention** | Retains messages | Deletes after consumption |
| **Use Case** | Event Streaming (Big Data, Logs) | Task Queueing (Email, Payments) |
| **Scalability** | High | Moderate |

ğŸš€ **Choose Kafka** â†’ If you need event streaming & log processing  
ğŸš€ **Choose RabbitMQ** â†’ If you need job queues & transactional tasks  

---

# **ğŸ“Œ Part 5: Next Steps**
âœ… **Play with Kafka & RabbitMQ!**  
âœ… **Simulate network failures and retry logic**  
âœ… **Next: CQRS & Event Sourcing**  

Would you like a **hands-on guide for CQRS & Event Sourcing** next? ğŸš€