# **ğŸ“… Day 8: Distributed Transactions & Sagas - Ensuring Data Consistency** ğŸš€  

Today, weâ€™ll dive into **Distributed Transactions & Sagas**, which help maintain **data consistency across microservices**. Weâ€™ll implement **a Saga Pattern using Kafka & Node.js** with a real-world example.  

---

## **ğŸ“Œ Part 1: What are Distributed Transactions?**
A **Distributed Transaction** updates data across multiple microservices/databases. If **one part fails, everything must roll back** to maintain consistency.  

### **ğŸ”¹ Why are they challenging?**
âŒ **Two-Phase Commit (2PC) is slow** â†’ Locks data across databases, reducing performance.  
âŒ **Network Failures** â†’ If one microservice fails, rollback becomes tricky.  
âŒ **Scalability Issues** â†’ Traditional transactions donâ€™t work well with microservices.  

**ğŸ’¡ Solution? Use the Saga Pattern!**  

---

## **ğŸ“Œ Part 2: What is the Saga Pattern?**
Saga is a **sequence of local transactions** where each step **triggers the next**, ensuring consistency **without locking databases**.  

### **ğŸ”¹ Types of Sagas**
1ï¸âƒ£ **Choreography (Event-Driven)** â†’ Each service **subscribes to events** from other services.  
2ï¸âƒ£ **Orchestration (Central Controller)** â†’ A **Saga Orchestrator** manages all service interactions.  

**ğŸ“¢ We will implement the Orchestration Saga Pattern using Kafka!**  

---

## **ğŸ“Œ Part 3: Hands-on Saga Pattern in Node.js**
We will create a **Food Order System** using 3 microservices:  
1ï¸âƒ£ **Order Service** â†’ Creates orders.  
2ï¸âƒ£ **Payment Service** â†’ Handles payments.  
3ï¸âƒ£ **Inventory Service** â†’ Checks stock availability.  
ğŸ”¹ **Kafka (Event Bus)** â†’ Passes events between services.  

---

## **ğŸ›  Step 1: Set Up Kafka & PostgreSQL with Docker**
ğŸ“ **Create `docker-compose.yml`**
```yaml
version: '3'
services:
  postgres:
    image: postgres
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: saga_db
    ports:
      - "5432:5432"

  kafka:
    image: bitnami/kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_CFG_ZOOKEEPER_CONNECT: "zookeeper:2181"
      ALLOW_PLAINTEXT_LISTENER: "yes"

  zookeeper:
    image: bitnami/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"
```

ğŸ”¥ **Start the containers**
```bash
docker-compose up -d
```

---

## **ğŸ›  Step 2: Install Node.js Dependencies**
```bash
npm init -y
npm install express pg kafka-node
```

---

## **ğŸ›  Step 3: Create the Order Service**
ğŸ“ **Create `orderService.js`**
```js
const express = require("express");
const kafka = require("kafka-node");

const app = express();
app.use(express.json());

const client = new kafka.KafkaClient({ kafkaHost: "localhost:9092" });
const producer = new kafka.Producer(client);

producer.on("ready", () => console.log("âœ… Kafka Producer is ready"));

app.post("/order", (req, res) => {
    const order = { orderId: Date.now(), product: req.body.product, status: "PENDING" };
    
    producer.send([{ topic: "order-created", messages: JSON.stringify(order) }], (err, data) => {
        if (err) return res.status(500).send("âŒ Kafka Error");
        console.log("ğŸ“¨ Order Created Event Sent:", order);
        res.status(201).send(order);
    });
});

app.listen(4000, () => console.log("ğŸš€ Order Service Running on Port 4000"));
```

---

## **ğŸ›  Step 4: Create the Payment Service**
ğŸ“ **Create `paymentService.js`**
```js
const express = require("express");
const { Pool } = require("pg");
const kafka = require("kafka-node");

const app = express();
const pool = new Pool({ user: "user", host: "localhost", database: "saga_db", password: "password", port: 5432 });

const client = new kafka.KafkaClient({ kafkaHost: "localhost:9092" });
const consumer = new kafka.Consumer(client, [{ topic: "order-created", partition: 0 }], { autoCommit: true });
const producer = new kafka.Producer(client);

consumer.on("message", async (message) => {
    const order = JSON.parse(message.value);
    
    const paymentSuccess = Math.random() > 0.2; // Simulate success (80% success rate)
    if (paymentSuccess) {
        order.status = "PAID";
        producer.send([{ topic: "payment-success", messages: JSON.stringify(order) }], () => {
            console.log("ğŸ’° Payment Successful Event Sent:", order);
        });
    } else {
        order.status = "FAILED";
        producer.send([{ topic: "payment-failed", messages: JSON.stringify(order) }], () => {
            console.log("âŒ Payment Failed Event Sent:", order);
        });
    }
});

app.listen(5000, () => console.log("ğŸš€ Payment Service Running on Port 5000"));
```

---

## **ğŸ›  Step 5: Create the Inventory Service**
ğŸ“ **Create `inventoryService.js`**
```js
const express = require("express");
const { Pool } = require("pg");
const kafka = require("kafka-node");

const app = express();
const pool = new Pool({ user: "user", host: "localhost", database: "saga_db", password: "password", port: 5432 });

const client = new kafka.KafkaClient({ kafkaHost: "localhost:9092" });
const consumer = new kafka.Consumer(client, [{ topic: "payment-success", partition: 0 }], { autoCommit: true });
const producer = new kafka.Producer(client);

consumer.on("message", async (message) => {
    const order = JSON.parse(message.value);
    
    const stockAvailable = Math.random() > 0.2; // Simulate stock availability
    if (stockAvailable) {
        order.status = "COMPLETED";
        producer.send([{ topic: "order-completed", messages: JSON.stringify(order) }], () => {
            console.log("ğŸ“¦ Order Completed Event Sent:", order);
        });
    } else {
        order.status = "OUT_OF_STOCK";
        producer.send([{ topic: "order-failed", messages: JSON.stringify(order) }], () => {
            console.log("âŒ Order Out of Stock Event Sent:", order);
        });
    }
});

app.listen(6000, () => console.log("ğŸš€ Inventory Service Running on Port 6000"));
```

---

## **ğŸ›  Step 6: Test the Saga Pattern**
### **ğŸ“Œ Create an Order**
```bash
curl -X POST http://localhost:4000/order -H "Content-Type: application/json" -d '{"product": "Phone"}'
```
ğŸ“¢ **Expected Output (Example)**
```
ğŸ“¨ Order Created Event Sent: { orderId: 171234567890, product: "Phone", status: "PENDING" }
ğŸ’° Payment Successful Event Sent: { orderId: 171234567890, status: "PAID" }
ğŸ“¦ Order Completed Event Sent: { orderId: 171234567890, status: "COMPLETED" }
```

---

## **ğŸ“Œ Part 5: Summary**
âœ… **Order Service** â†’ Creates orders & sends Kafka event  
âœ… **Payment Service** â†’ Listens for events, processes payment  
âœ… **Inventory Service** â†’ Checks stock, finalizes order  
âœ… **Kafka** â†’ Passes events between services  

---

# **ğŸ“Œ Part 6: Next Steps**
ğŸš€ **Try Compensation Transactions** â†’ Rollback payments if inventory fails  
ğŸš€ **Implement a Saga Orchestrator** â†’ Centralize the workflow  
ğŸš€ **Next: API Rate Limiting & Throttling**  

Would you like a **hands-on guide for API Rate Limiting next?** ğŸ”¥