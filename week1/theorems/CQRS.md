# **ğŸ“… Day 7: CQRS & Event Sourcing - Designing Scalable & Reliable Systems ğŸš€**  

Today, weâ€™ll dive into **CQRS (Command Query Responsibility Segregation) and Event Sourcing** with **hands-on implementation using Node.js, Kafka, and PostgreSQL.**  

---

## **ğŸ“Œ Part 1: What is CQRS?**
CQRS stands for **Command Query Responsibility Segregation** and separates **read (Query) and write (Command) operations** into different models.  

### **ğŸ”¹ Why Use CQRS?**
âœ… **Scalability** â†’ Read and write operations scale independently  
âœ… **Performance** â†’ Optimized database schema for queries vs updates  
âœ… **Security** â†’ Restrict write operations while allowing broader read access  

### **ğŸ”¹ CQRS Architecture**
- **Command Service** â†’ Handles **writes** (Create, Update, Delete)  
- **Query Service** â†’ Handles **reads** (Fetching data)  
- **Event Bus** â†’ Kafka/RabbitMQ sends **changes** from Command â†’ Query  

---

## **ğŸ“Œ Part 2: What is Event Sourcing?**
**Event Sourcing stores every state change as an immutable event, rather than just storing the current state.**  
Instead of "overwriting" data, we **append new events** to a log.  

### **ğŸ”¹ Why Use Event Sourcing?**
âœ… **Auditability** â†’ Complete history of all changes  
âœ… **Rebuilding State** â†’ Reconstruct system state by replaying events  
âœ… **Fault Tolerance** â†’ Store events safely, recover lost data  

ğŸ“¢ **Example:**
Instead of just storing `{ balance: 100 }`, we store:  
1ï¸âƒ£ `Deposit $50`  
2ï¸âƒ£ `Withdraw $30`  
3ï¸âƒ£ `Deposit $80`  
ğŸ’¡ We can **replay** these events to get `{ balance: 100 }`  

---

# **ğŸ“Œ Part 3: Hands-on CQRS & Event Sourcing with Node.js**
We will create:  
1ï¸âƒ£ **Command Service** (Handles writes)  
2ï¸âƒ£ **Query Service** (Handles reads)  
3ï¸âƒ£ **Kafka Event Bus** (Handles event communication)  
4ï¸âƒ£ **PostgreSQL Database** (Stores event data)  

---

## **ğŸ›  Step 1: Set Up Kafka & PostgreSQL with Docker**
ğŸ“ **Create `docker-compose.yml`**
```yaml
version: '3'
services:
  postgres:
    image: postgres
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: cqrs_db
    ports:
      - "5432:5432"

  kafka:
    image: bitnami/kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_CFG_ZOOKEEPER_CONNECT: "zookeeper:2181"
      ALLOW_PLAINTEXT_LISTENER: "yes"

  zookeeper:
    image: bitnami/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"
```

ğŸ”¥ **Start the containers**
```bash
docker-compose up -d
```

---

## **ğŸ›  Step 2: Install Node.js Dependencies**
```bash
npm init -y
npm install express pg kafka-node
```

---

## **ğŸ›  Step 3: Create the Command Service (Write API)**
ğŸ“ **Create `commandService.js`**
```js
const express = require("express");
const kafka = require("kafka-node");

const app = express();
app.use(express.json());

// Kafka Producer Setup
const client = new kafka.KafkaClient({ kafkaHost: "localhost:9092" });
const producer = new kafka.Producer(client);

// Ensure Kafka is ready
producer.on("ready", () => console.log("âœ… Kafka Producer is ready"));
producer.on("error", (err) => console.error("Kafka Producer Error:", err));

// Create Order API (Write)
app.post("/order", (req, res) => {
    const order = { orderId: Date.now(), product: req.body.product, quantity: req.body.quantity };
    
    producer.send([{ topic: "order-events", messages: JSON.stringify(order) }], (err, data) => {
        if (err) return res.status(500).send("âŒ Kafka Error");
        console.log("ğŸ“¨ Order Created Event Sent:", order);
        res.status(201).send(order);
    });
});

app.listen(4000, () => console.log("ğŸš€ Command Service Running on Port 4000"));
```

---

## **ğŸ›  Step 4: Create the Query Service (Read API)**
ğŸ“ **Create `queryService.js`**
```js
const express = require("express");
const { Pool } = require("pg");
const kafka = require("kafka-node");

const app = express();
const pool = new Pool({ user: "user", host: "localhost", database: "cqrs_db", password: "password", port: 5432 });

// Kafka Consumer Setup
const client = new kafka.KafkaClient({ kafkaHost: "localhost:9092" });
const consumer = new kafka.Consumer(client, [{ topic: "order-events", partition: 0 }], { autoCommit: true });

// Store event in DB when received
consumer.on("message", async (message) => {
    const order = JSON.parse(message.value);
    await pool.query("INSERT INTO orders (order_id, product, quantity) VALUES ($1, $2, $3)", 
        [order.orderId, order.product, order.quantity]);
    console.log("ğŸ“¥ Order Event Stored in DB:", order);
});

// Fetch Orders API (Read)
app.get("/orders", async (req, res) => {
    const result = await pool.query("SELECT * FROM orders");
    res.json(result.rows);
});

app.listen(5000, () => console.log("ğŸš€ Query Service Running on Port 5000"));
```

ğŸ“ **Create `initDB.sql`**
```sql
CREATE TABLE orders (
    id SERIAL PRIMARY KEY,
    order_id BIGINT UNIQUE NOT NULL,
    product TEXT NOT NULL,
    quantity INT NOT NULL
);
```

ğŸ”¥ **Initialize Database**
```bash
psql -h localhost -U user -d cqrs_db -f initDB.sql
```

---

## **ğŸ›  Step 5: Test the Implementation**
### **ğŸ“Œ Create an Order (Command Service)**
```bash
curl -X POST http://localhost:4000/order -H "Content-Type: application/json" -d '{"product": "Laptop", "quantity": 1}'
```
ğŸ“¢ **Expected Output:**
```
ğŸ“¨ Order Created Event Sent: { orderId: 171234567890, product: "Laptop", quantity: 1 }
```

---

### **ğŸ“Œ Fetch Orders (Query Service)**
```bash
curl -X GET http://localhost:5000/orders
```
ğŸ“¢ **Expected Output:**
```json
[
  { "order_id": 171234567890, "product": "Laptop", "quantity": 1 }
]
```

---

## **ğŸ“Œ Part 4: Summary**
âœ… **Command Service** â†’ Sends order events via Kafka  
âœ… **Query Service** â†’ Listens for events and stores data in PostgreSQL  
âœ… **Kafka** â†’ Acts as an **Event Bus**  
âœ… **PostgreSQL** â†’ Stores **read-optimized data**  

---

# **ğŸ“Œ Part 5: Next Steps**
ğŸš€ **Try Scaling Services** â†’ Run multiple instances of `queryService.js`  
ğŸš€ **Implement Event Replay** â†’ Replay events to rebuild state  
ğŸš€ **Next: Distributed Transactions & Sagas**  

Would you like a **hands-on guide for Distributed Transactions & Sagas** next? ğŸ”¥