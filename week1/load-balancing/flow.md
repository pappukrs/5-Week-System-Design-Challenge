### **ğŸ“… Day 3: Load Balancing - Distributing Traffic Efficiently**  

---

## **ğŸš€ What is Load Balancing?**  
Load balancing is a technique used to distribute incoming network traffic across multiple servers, ensuring no single server is overwhelmed. It improves:  

âœ… **Scalability** - Handles increasing traffic smoothly  
âœ… **High Availability** - Prevents server crashes due to overload  
âœ… **Performance Optimization** - Distributes traffic efficiently  

---

## **ğŸŒ Types of Load Balancers**  

### **1ï¸âƒ£ DNS Load Balancing**
- Distributes traffic at the **DNS level** by returning different server IPs based on geographic proximity or round-robin logic.
- Example: **AWS Route 53, Cloudflare Load Balancer**  

**ğŸ›  How It Works?**  
- User requests `myapp.com` â†’ DNS rotates IPs â†’ Requests are distributed  

**âš ï¸ Limitation:**  
- Cannot dynamically adjust based on server health.  

---

### **2ï¸âƒ£ Software Load Balancers**
These are installed on a server and used for routing traffic between multiple backend servers.  

ğŸ”¹ **Popular Software Load Balancers:**  
- **NGINX** (Reverse Proxy + Load Balancer)  
- **HAProxy** (High-performance Load Balancer)  

**âœ… Advantages:**  
âœ” Customizable configurations  
âœ” Supports different load balancing algorithms  
âœ” Monitors server health  

---

### **3ï¸âƒ£ Hardware Load Balancers**
- **Dedicated network appliances** for traffic distribution.  
- Used by **large enterprises** with high traffic demands.  

ğŸ”¹ **Examples:**  
- **F5 Big-IP**, **Citrix NetScaler**, **Cisco Load Balancers**  

âœ… **Advantages:**  
âœ” Super fast and low latency  
âœ” Built-in DDoS protection  

âŒ **Downside:** Expensive & requires specialized hardware.  

---

## **âš™ Load Balancing Algorithms**
Load balancers use different **algorithms** to decide where to send requests.  

### **1ï¸âƒ£ Round Robin** (Default)
- **How it Works?**  
  - Distributes requests **sequentially** to all available servers.  
  - Example:  
    ```
    Request 1 â†’ Server A  
    Request 2 â†’ Server B  
    Request 3 â†’ Server C  
    Request 4 â†’ Server A  
    ```
âœ… **Good for:** Balanced loads where all servers are equal.  
âŒ **Bad for:** Unequal load servers (e.g., one is slower).  

---

### **2ï¸âƒ£ Least Connections**
- **How it Works?**  
  - Sends traffic to the server with **fewer active connections.**  
âœ… **Good for:** Long-lived connections like WebSockets.  
âŒ **Bad for:** Short, quick HTTP requests (less useful).  

---

### **3ï¸âƒ£ IP Hashing**
- **How it Works?**  
  - Routes requests based on the clientâ€™s **IP address**.  
  - Ensures the **same user always** hits the same server.  

âœ… **Good for:** Sticky sessions & consistent user experience.  
âŒ **Bad for:** Load imbalances if one user sends too many requests.  

---

## **ğŸ” Activity: Set Up an NGINX Load Balancer**  

### **ğŸ›  Step 1: Create Multiple Node.js Servers**  
ğŸ“ **Create `server1.js`**  
```js
const express = require('express');
const app = express();
app.get('/', (req, res) => {
    res.send('Hello from Server 1');
});
app.listen(3001, () => console.log('Server 1 running on port 3001'));
```

ğŸ“ **Create `server2.js`**  
```js
const express = require('express');
const app = express();
app.get('/', (req, res) => {
    res.send('Hello from Server 2');
});
app.listen(3002, () => console.log('Server 2 running on port 3002'));
```

ğŸ“ **Create `server3.js`**  
```js
const express = require('express');
const app = express();
app.get('/', (req, res) => {
    res.send('Hello from Server 3');
});
app.listen(3003, () => console.log('Server 3 running on port 3003'));
```

---

### **ğŸ›  Step 2: Create an NGINX Load Balancer Configuration**
ğŸ“ **Create `nginx.conf`**  
```nginx
events {}

http {
    upstream backend_servers {
        server server1:3001;
        server server2:3002;
        server server3:3003;
    }

    server {
        listen 80;

        location / {
            proxy_pass http://backend_servers;
        }
    }
}
```

---

### **ğŸ›  Step 3: Create a Docker Compose File**
ğŸ“ **Create `docker-compose.yml`**  
```yaml
version: '3'

services:
  server1:
    build: ./server1
    ports:
      - "3001:3001"

  server2:
    build: ./server2
    ports:
      - "3002:3002"

  server3:
    build: ./server3
    ports:
      - "3003:3003"

  nginx:
    image: nginx:latest
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    ports:
      - "80:80"
    depends_on:
      - server1
      - server2
      - server3
```

---

### **ğŸ›  Step 4: Run Everything**
1ï¸âƒ£ **Start the services:**  
```bash
docker-compose up -d
```

2ï¸âƒ£ **Test Load Balancer:**  
```bash
curl http://localhost
```
â¡ Youâ€™ll see responses like:  
```
Hello from Server 1
Hello from Server 2
Hello from Server 3
```
ğŸ¯ **NGINX is now distributing traffic!**  

---

## **ğŸš€ Conclusion**
âœ… **Round Robin is the default algorithm** (works best when servers are equal).  
âœ… **Least Connections** is best for **long-lived connections** like WebSockets.  
âœ… **IP Hashing** ensures **users always hit the same server** (good for sessions).  

**ğŸ›  Next Steps:**  
ğŸ”¹ Try different **load balancing algorithms** in `nginx.conf`  
ğŸ”¹ Set up **Health Checks** to remove failed servers  

---

ğŸ”¥ **Question:** Want to explore **Load Balancing in Kubernetes** next? ğŸš€